{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "amended-worship",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "temporal-export",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeeded to open the port\n",
      "Succeeded to change the baudrate\n"
     ]
    }
   ],
   "source": [
    "# Camera libraries\n",
    "import traitlets\n",
    "import ipywidgets\n",
    "from IPython.display import display\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "\n",
    "# Servo librarie\n",
    "from SCSCtrl import TTLServo\n",
    "\n",
    "# Motor librarie\n",
    "from jetbot import Robot\n",
    "\n",
    "# OpenCV librarie\n",
    "import cv2\n",
    "\n",
    "# Utilities\n",
    "import time\n",
    "import numpy as np\n",
    "import threading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amended-culture",
   "metadata": {},
   "source": [
    "# Global variables and camera setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "canadian-timothy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Width and Height of the screen\n",
    "screen_w = 300\n",
    "screen_h = 300\n",
    "\n",
    "# Red\n",
    "lower_red = np.array([160, 100, 100])\n",
    "upper_red = np.array([180, 255, 255])\n",
    "\n",
    "# Yellow/Orange\n",
    "lower_yellow = np.array([0, 50, 0])\n",
    "upper_yellow = np.array([30, 255, 255])\n",
    "\n",
    "# Blue/Purpel\n",
    "lower_blue = np.array([90, 100, 100])\n",
    "upper_blue = np.array([120, 255, 200])\n",
    "\n",
    "# Minimum size a contour need to be\n",
    "min_cnt_size = 50\n",
    "\n",
    "# X and Y coordinates the duplo bricks need to be at in order for the arm to grab it\n",
    "grab_zone_x = 140\n",
    "grab_zone_y = 240\n",
    "\n",
    "# An margin of error for the x,y above so pixel coordinates don't have to aline 100% (That would be pretty hard)\n",
    "error_margin = 10\n",
    "\n",
    "# Instansiate the robot and a speed to move with\n",
    "robot = Robot()\n",
    "speed = 0.3\n",
    "\n",
    "# Set the servos at initial position\n",
    "TTLServo.servoAngleCtrl(1, 0, 1, 150)\n",
    "TTLServo.servoAngleCtrl(2, 0, 1, 150)\n",
    "TTLServo.servoAngleCtrl(3, 0, 1, 150)\n",
    "TTLServo.servoAngleCtrl(4, 0, 1, 150)\n",
    "TTLServo.servoAngleCtrl(5, 0, 1, 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stretch-berry",
   "metadata": {},
   "source": [
    "We need to start the camera feed here as part of the variables, since we need to keep track of the number of threads that are running when we start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "stone-prince",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "142731909b5a42ecb8f41729eb43399a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C\\x00\\x02\\x01\\x0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create camere\n",
    "camera = Camera.instance(width = screen_w, height = screen_h)\n",
    "\n",
    "# Create widget\n",
    "image_widget = ipywidgets.Image()\n",
    "\n",
    "# Link the camera and widget\n",
    "camera_link = traitlets.dlink((camera, 'value'), (image_widget, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "# Display the camera feed using the widget\n",
    "display(image_widget)\n",
    "\n",
    "# We can now store all the active threads we are running\n",
    "threads = threading.active_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "roman-peeing",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suitable-monthly",
   "metadata": {},
   "source": [
    "We are gonna need three functions for this project.\n",
    "- A function that picks up a place the duplo bricks in the basket\n",
    "- A function that locates the duplo bricks\n",
    "- A function that drives to the duplo bricks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genetic-lindsay",
   "metadata": {},
   "source": [
    "## grab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "central-found",
   "metadata": {},
   "source": [
    "The grab functio will grab bricks in front of the robot then swing the arm to the back of the robot where a basket is attached and drop the bricks in the basket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "right-company",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grap function\n",
    "def grab():\n",
    "    \n",
    "    # GRAB\n",
    "    # Position arm down\n",
    "    TTLServo.xyInput(200, -90)\n",
    "    time.sleep(1)\n",
    "    # Close grip\n",
    "    TTLServo.servoAngleCtrl(4, 40, -1, 150)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # PLACE IN BASKET\n",
    "    # Position arm at back\n",
    "    TTLServo.servoAngleCtrl(2, 100, -1, 200)\n",
    "    TTLServo.servoAngleCtrl(3, 100, 1, 200)\n",
    "    time.sleep(5)\n",
    "    # Open grib\n",
    "    TTLServo.servoAngleCtrl(4, 100, 1, 150)\n",
    "    time.sleep(3)\n",
    "    # Position arm at initial position\n",
    "    TTLServo.servoAngleCtrl(2, 0, 1, 200)\n",
    "    TTLServo.servoAngleCtrl(3, 0, 1, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "referenced-straight",
   "metadata": {},
   "source": [
    "## find_toy_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "harmful-illustration",
   "metadata": {},
   "source": [
    "The find_toy_pos function takes a images from the camre and filters for different colours that the duplo bricks have. Then contours of the bricks are obtained and the brick with the biggest contour (we are asumening this means it is closest to the robot) are selected if it is bigger then the minimum size we have selected, and a bounding box is calculated and drawn on the input images aswell as the center of the bounding box. The center x,y is then returned. If no contour was obtained or the biggest counter found was samller then the minimum size '-1,-1' is returned insted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "controlled-soundtrack",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_toy_pos(input_image):\n",
    "    \n",
    "    # Convert video frames to HSV color space.\n",
    "    hsv = cv2.cvtColor(input_image, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Create masks for pixels that match the target colors.\n",
    "    mask_red = cv2.inRange(hsv, lower_red, upper_red)\n",
    "    \n",
    "    mask_yellow = cv2.inRange(hsv, lower_yellow, upper_yellow)\n",
    "    \n",
    "    mask_blue = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "    \n",
    "    # Combining the masks\n",
    "    result = mask_red + mask_yellow + mask_blue\n",
    "    \n",
    "    # Erode, this process will remove the relatively \n",
    "    # small area in the mask just selected, which can be understood as denoising.\n",
    "    result = cv2.erode(result, None, iterations=1)\n",
    "\n",
    "    # dilate, the corrosion process just now will cause the large area to become \n",
    "    # smaller and the small area to disappear. This step is to restore the large area to its previous size.\n",
    "    result = cv2.dilate(result, None, iterations=1)\n",
    "    \n",
    "    # Obtain the conformed area contour.\n",
    "    cnts = cv2.findContours(result.copy(), cv2.RETR_EXTERNAL,\n",
    "        cv2.CHAIN_APPROX_SIMPLE)[-2]\n",
    "    center = None\n",
    "    \n",
    "    # Check if there is any contours\n",
    "    if len(cnts) > 0:\n",
    "        \n",
    "        # Get the biggest contour\n",
    "        c = max(cnts, key=cv2.contourArea)\n",
    "        \n",
    "        # Check if the area is bigger than the minimum size\n",
    "        if cv2.contourArea(c) > min_cnt_size:\n",
    "            \n",
    "            # Make a bounding box and get the values\n",
    "            x, y, w, h = cv2.boundingRect(c)\n",
    "            \n",
    "            # Calculate center of the bounding box\n",
    "            center_x = int(x + (w / 2))\n",
    "            center_y = int(y + (h / 2))\n",
    "            \n",
    "            # Draw a circle at the center and the bounding box\n",
    "            cv2.circle(input_image, (center_x, center_y), 2, (255, 255, 255), -1)\n",
    "            cv2.rectangle(input_image, (x, y), (x + w, y + h), (255, 255, 255), 1)\n",
    "            \n",
    "            # Return the center x,y\n",
    "            return center_x, center_y\n",
    "    \n",
    "    # else return -1,-1\n",
    "        else:\n",
    "            return -1, -1\n",
    "    else:\n",
    "        return -1, -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compact-stroke",
   "metadata": {},
   "source": [
    "## drive_to_position"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lightweight-whale",
   "metadata": {},
   "source": [
    "The drive_to_position function checks where the x,y coordinates of the duplo brick, found with the find_toy_pos funtion, is in relationship to where it should be in order for the robot arm to grab it. We know (by trail and error) at what position the center of the brick should be at in the images (+/- an error margin) in order for the arm to grab it. When the brick is at the position it needs to be the funtion returns true.\n",
    "\n",
    "For example, can we check if the bricks x coordinate is less than the position we want it to be at, the brick is to our left and we then turn the robot to the left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "working-finder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drive_to_position(input_image, zone_x, zone_y, center_x, center_y):\n",
    "    \n",
    "    #Left/Right\n",
    "    \n",
    "    # This means find_toy_pos() did not find any duplo bricks\n",
    "    if center_x < 0:\n",
    "        # Stop the robot, draw the grab zone\n",
    "        robot.stop()\n",
    "        cv2.circle(input_image, (zone_x, zone_y), error_margin, (0, 0, 0), 1)\n",
    "        \n",
    "        # The brick is to the left\n",
    "    elif center_x < zone_x - error_margin:\n",
    "        # Truns left, draw the grab zone and write what turn we are making\n",
    "        robot.left(speed)\n",
    "        cv2.putText(input_image, 'Left', (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "        cv2.circle(input_image, (zone_x, zone_y), error_margin, (0, 0, 0), 1)\n",
    "        \n",
    "        # The brick is to the right\n",
    "        cv2.circle(input_image, (zone_x, zone_y), error_margin, (0, 0, 0), 1)\n",
    "    elif center_x > zone_x + error_margin:\n",
    "        # Truns left, draw the grab zone and write what turn we are making\n",
    "        robot.right(speed)\n",
    "        cv2.putText(input_image, 'Right', (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "        cv2.circle(input_image, (zone_x, zone_y), error_margin, (0, 0, 0), 1)  \n",
    "    \n",
    "    # Forward/Backward\n",
    "    \n",
    "    # This means find_toy_pos() did not find any duplo bricks\n",
    "    if center_y < 0:\n",
    "        # Stop the robot, draw the grab zone\n",
    "        robot.stop()\n",
    "        cv2.circle(input_image, (zone_x, zone_y), error_margin, (0, 0, 0), 1)\n",
    "        \n",
    "        # The brick is in front of the the grab zone\n",
    "    elif center_y < zone_y - error_margin:\n",
    "        # Drives forward, draw the grab zone and write the direction\n",
    "        robot.forward(speed)\n",
    "        cv2.putText(input_image, 'Forward', (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "        cv2.circle(input_image, (zone_x, zone_y), error_margin, (0, 0, 0), 1)\n",
    "        \n",
    "        # The brick is behind the grab zone\n",
    "    elif center_y > zone_y + error_margin:\n",
    "        # Drives backwards, draw the grab zone and write the direction\n",
    "        robot.backward(speed)\n",
    "        cv2.putText(input_image, 'Backwards', (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "        cv2.circle(input_image, (zone_x, zone_y), error_margin, (0, 0, 0), 1)\n",
    "        \n",
    "        # The bricks center is in the grab zone\n",
    "    if center_x > zone_x - error_margin and center_x < zone_x + error_margin and center_y > zone_y - error_margin and center_y < zone_y + error_margin:\n",
    "        # Stop the robot, draw the grab zone, returns true\n",
    "        robot.stop()\n",
    "        cv2.circle(input_image, (zone_x, zone_y), error_margin, (255, 255, 255), 1)\n",
    "        return True\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-patrol",
   "metadata": {},
   "source": [
    "## execute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "durable-richmond",
   "metadata": {},
   "source": [
    "The execute function basicly funtions as our main loop and ties all the functions together with the camera feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "generic-harvest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practicly the \"game loop\"\n",
    "def execute(change):\n",
    "    # Global variable\n",
    "    global grab_zone_x, grab_zone_y, grab_proccess, threads\n",
    "    \n",
    "    # Get the new images\n",
    "    image = change['new']\n",
    "    \n",
    "    # Check if there is no more active threds than when we started\n",
    "    if threading.active_count() <= threads:\n",
    "        \n",
    "        # Finds a duplo bricks cneter coordinated\n",
    "        center_x, center_y = find_toy_pos(image)\n",
    "        \n",
    "        # Drive over to the brick\n",
    "        in_position = drive_to_position(image, grab_zone_x, grab_zone_y, center_x, center_y)\n",
    "        \n",
    "        # If we are at teh brick\n",
    "        if in_position:\n",
    "            # Starte the grab function in a new thread. This is to avoid the camera feed from freezing.\n",
    "            grab_thread = threading.Thread(target = grab)\n",
    "            grab_thread.start()\n",
    "        \n",
    "    # Display the images\n",
    "    image_widget.value = bgr8_to_jpeg(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brilliant-lodge",
   "metadata": {},
   "source": [
    "# Start everything"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welcome-shoulder",
   "metadata": {},
   "source": [
    "Lastly we need to link the camera with the executa funtion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "informative-patio",
   "metadata": {},
   "outputs": [],
   "source": [
    "execute({'new': camera.value})\n",
    "camera.unobserve_all()\n",
    "camera.observe(execute, names='value')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "micro-start",
   "metadata": {},
   "source": [
    "# Stop everyrhing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adjusted-technique",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.unobserve(execute, names='value')\n",
    "time.sleep(1)\n",
    "camera.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
